```{r warning=FALSE, error=FALSE}
library(caret)
library(randomForest) 
library(rpart)
library(rpart.plot) 
```

# setting the overall seed for reproduceability
```{r warning=FALSE, error=FALSE}
set.seed(6666)
```

# Loading the training data set and testing data while replacing all missing with "NA"
```{r warning=FALSE, error=FALSE}
trainingset <- read.csv("C:/Users/Chen Chen/Desktop/8、Practical Machine Learning/pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testingset <- read.csv("C:/Users/Chen Chen/Desktop/8、Practical Machine Learning/pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
```

# Check dimensions for number of variables and number of observations.
```{r warning=FALSE, error=FALSE}
dim(trainingset)
dim(testingset)
```

# Columns with all missing values in the two data sets were deleted.  
```{r warning=FALSE, error=FALSE}
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
```

# Deleted variables that are irrelevant with prediction (x, user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window, that are columns 1 to 7).
```{r warning=FALSE, error=FALSE}
trainingset <- trainingset[,-c(1:7)]
testingset <- testingset[,-c(1:7)]
```

# Had a look at the new datasets.
```{r warning=FALSE, error=FALSE}
dim(trainingset)
dim(testingset)
head(trainingset)
head(testingset)
```

# To perform cross-validation, the training data set is partionned into 2 sets: subTraining (75%) and subTest (25%). This will be performed using random subsampling without replacement.
```{r warning=FALSE, error=FALSE}
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ] 
subTesting <- trainingset[-subsamples, ]
dim(subTraining)
dim(subTesting)
head(subTraining)
head(subTesting)
```

# Visulized the data.
```{r warning=FALSE, error=FALSE}
plot(subTraining$classe, col="red", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
```

# Used Decision Tree as the first prediction model.
# Prediction using the first model.
```{r warning=FALSE, error=FALSE}
DT <- rpart(classe ~ ., data=subTraining, method="class")

DT

prediction_01 <- predict(DT, subTesting, type = "class")
```

# Plot of the Decision Tree.
```{r warning=FALSE, error=FALSE}
rpart.plot(DT, main="Classification Tree", extra=102, under=TRUE, faclen=0)
```

# Tested results on our subTesting data set.
```{r warning=FALSE, error=FALSE}
confusionMatrix(prediction_01, subTesting$classe)
```

# Used Random Forest as the second prediction model. 
```{r warning=FALSE, error=FALSE}
RF <- randomForest(classe ~. , data=subTraining, method="class")
```

# Prediction using the RF model.
```{r warning=FALSE, error=FALSE}
prediction_02 <- predict(RF, subTesting, type = "class")
```

# Tested results on subTesting data set.
```{r warning=FALSE, error=FALSE}
confusionMatrix(prediction_02, subTesting$classe)
```
